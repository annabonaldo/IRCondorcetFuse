\input{style.sty}

\begin{document}
    \printTitle
    \newpage
    \tableofcontents
    \newpage
    %\listoftables
    %\listoffigures
    \section{Abstract}
    In Information Retrieval, data fusion is the combination of the results
    of independent searches on a document collection into one single output
    result set.

    It has been shown in the past that this can greatly improve retrieval
    effectiveness over that of the individual results.

    The aim of this project is to show a possible implementation of basic
    fusion strategy and an advanced one: Condorcet fusion.

    %Qualche conclusione

    \section{Introduction}

    In this project the input documents were taken from the TREC ad hoc collection
	TIPSTER Collection. The ground-truth and topics files associated were also taken
	into account during the evaluation phase.
    
    The following procedure illustrates the organization of the work:

    \begin{itemize}
        \item \textbf{Indexing} (with or without query expansion)
        \item \textbf{Retrieval} (10 different retrieval models)
		\item \textbf{Normalization} (min/max normalization)
        \item \textbf{Fusion strategy} (with or without cutting the run at depth 100)
            \begin{itemize}
                \item 6 basic strategies
                \item Condorcet fusion (advanced strategy)
            \end{itemize}
    \end{itemize}
    
    \begin{table}[H]
        \centering
        \begin{tabular}{c}
		\toprule
        \textbf{Retrieval models} \\ \toprule
        BB2 \\
        BM25 \\
        DLH13 \\
        Hiemstra\_LM \\
        IFB2 \\
        TF\_IDF \\
        DFIC \\
        DFIZ \\
        DirichletLM \\
        InL2 \\
        \bottomrule
        \end{tabular}
        \caption{Retrieval models used}
    \end{table}

    \section{Basic fusion strategies}

    The following table shows a list of basic fusion methods:

    \begin{table}[H]
        \centering
        \begin{tabular}{c p{4cm}}
        \toprule
        \textbf{Basic fusion methods} & \textbf{New score} \\ \toprule
        CombMNZ & SUM(Individual similarities)*Nonzero similarities \\ \hline
        CombSUM & SUM(Individual similarities) \\ \hline
        CombMIN & MIN(Individual similarities) \\ \hline
        CombMAX & MAX(Individual similarities) \\ \hline
        CombMED & MED(Individual similarities) \\ \hline
        CombANZ & SUM(Individual similarities)/Nonzero similarities \\ \bottomrule
        \end{tabular}
        \caption{Basic fusion methods used}
    \end{table}
    
    \section{Condorcet fusion}

    The Condorcet voting algorithm is a majoritarian method which specifies
    that the ``winner'' of the fusion is the document(s) that beats or ties
    with every other document in a pair-wise comparison between the input
    systems (i.e. runs).

	\subsection{The Condorcet Graph}

	Given 10 models of retrieval with n documents, the corresponding
	Condorcet graph $G = (V, E)$ has one vertex for each of the n documents.

	For each document pair (x, y), there exists an edge from x to
	y (denoted by $x \rightarrow y$) if x would have at least a score
    equal as y in a head-to-head contest.

	Cyces can simply be viewed as ties.

	The relative ordering of documents within a cycle is only of
	secondary importance, whereas their ordering with respect
	to the rest of the documents is of primary importance.

	\subsection{Condorcet paths}

	A Condorcet-consistent hamiltonian path (or condorcet path) is any
	hamiltonian path through the Condorcet graph.

	The goal is to efficiently find such a path.

    \section{Implementation}

	The main project structure is the following:
	
	\begin{itemize}
	\item \textbf{eval/} Contains evaluation scripts.
	\item \textbf{results/} Contains input and output runs for fusion.
	\item \textbf{scripts/} Contains indexing and retrieval scripts.
	\item \textbf{src/} Main directory of the application, contains Java source code.
		\begin{itemize}
		\item Base/ Contains definition for run, runset and min/max normalization.
		\item Fusion/ Contains implementation of basic fusion methods and Condorcet.
		\item IO/ Manages the input and output of runs.
		\item Application - the main class.
		\end{itemize}
	\end{itemize}

    The implementation of Condorcet used quicksort, with the following algorithm
	as comparing function:

	\begin{lstlisting}
	count = 0
	for each of the k search systems do:
	  if sys i ranks d1 above d2, count++
	  if sys i ranks d2 above d1, count--
	  if count > 0, rank d1 better than d2
	  else rank d2 better than d1
	\end{lstlisting}

    \section{Evaluation}
    % Modelli scelti 
    % Indicizzazione utilizzata

	The evaluation criteria based on the given pool used two binary relevance scores:
	Relevant and Non-Relevant.
	The documents left out from the pool were considered to be non relevant.

        \subsection{Evaluation metrics}
		% Perche abbiamo usato solo la MAP 
		% Perche' si fanno questi confronti

	    \subsection{Results}

		\begin{table}[H]
		    \centering
		    \begin{tabular}{c p{4cm}}
		    \toprule
		    \textbf{Fusion methods} & \textbf{MAP} \\ \toprule
		    CombMNZ &  \\ \hline
		    CombSUM &  \\ \hline
		    CombMIN &  \\ \hline
		    CombMAX &  \\ \hline
		    CombMED &  \\ \hline
		    CombANZ &  \\ \hline
			Condorcet &  \\ \bottomrule
		    \end{tabular}
		    \caption{Mean Average Precision for the 10 fused runs}
		\end{table}

	\section{Conclusions}
	

\end{document}
